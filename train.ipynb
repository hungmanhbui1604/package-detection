{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7869b9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import DataParallel\n",
    "import torchvision.transforms as T\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dataloaders import PackageTrainDataset, PackageTestDataset\n",
    "from models import MyModel\n",
    "from metrics import MCE, OE, AC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0c93ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_RATIO = 0.08\n",
    "RANDOM_SEED = 42\n",
    "X, Y, W, H = 560, 150, 300, 330\n",
    "ROI = (X, Y, X + W, Y + H)  # (left, upper, right, lower)\n",
    "NUM_POINTS = 32768  # 32\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4\n",
    "PIN_MEMORY = True\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 1e-5\n",
    "NUM_EPOCHS = 100\n",
    "LAMBDA = 3.6\n",
    "\n",
    "train_dir = './data/Train/'\n",
    "train_label_dir = train_dir + 'Public train.csv'\n",
    "train_rgb_dir = train_dir + 'rgb/'\n",
    "train_depth_dir = train_dir + 'depth/'\n",
    "train_ply_dir = train_dir + 'ply/'\n",
    "\n",
    "test_dir = './data/Test/'\n",
    "test_rgb_dir = test_dir + 'rgb/'\n",
    "test_depth_dir = test_dir + 'depth/'\n",
    "test_ply_dir = test_dir + 'ply/'\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a1c61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(train_label_dir)\n",
    "train_df, val_df = train_test_split(\n",
    "    df,\n",
    "    test_size=VALIDATION_RATIO,\n",
    "    random_state=RANDOM_SEED,\n",
    "    shuffle=True\n",
    ")\n",
    "print(f\"Training set size: {len(train_df)}\")\n",
    "print(f\"Validation set size: {len(val_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fdf578",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_transforms = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "depth_transforms = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.5], std=[0.5]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6deee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = PackageTrainDataset(\n",
    "    df=train_df, \n",
    "    rgb_dir=train_rgb_dir,\n",
    "    depth_dir=train_depth_dir,\n",
    "    ply_dir=train_ply_dir,\n",
    "    roi=ROI,\n",
    "    num_points=NUM_POINTS,\n",
    "    rgb_transform=rgb_transforms,\n",
    "    depth_transform=depth_transforms,\n",
    "    ply_transform=True\n",
    ")\n",
    "\n",
    "val_set = PackageTrainDataset(\n",
    "    df=val_df, \n",
    "    rgb_dir=train_rgb_dir,\n",
    "    depth_dir=train_depth_dir,\n",
    "    ply_dir=train_ply_dir,\n",
    "    roi=ROI,\n",
    "    num_points=NUM_POINTS,\n",
    "    rgb_transform=rgb_transforms,\n",
    "    depth_transform=depth_transforms,\n",
    "    ply_transform=True\n",
    ")\n",
    "test_set = PackageTestDataset(\n",
    "    rgb_dir=test_rgb_dir,\n",
    "    depth_dir=test_depth_dir,\n",
    "    ply_dir=test_ply_dir,\n",
    "    roi=ROI,\n",
    "    num_points=NUM_POINTS,\n",
    "    rgb_transform=rgb_transforms,\n",
    "    depth_transform=depth_transforms,\n",
    "    ply_transform=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d27047a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    dataset=train_set,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=PIN_MEMORY\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_set,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=PIN_MEMORY\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_set,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=PIN_MEMORY\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c841d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(weights=None).to(device)\n",
    "model = DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3745dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10)\n",
    "coordinate_criterion = torch.nn.MSELoss()\n",
    "angle_criterion = torch.nn.CosineEmbeddingLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbaacfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {\"train_loss\": [], \"val_loss\": [], \"val_mce\": [], \"val_oe\": [], \"val_ac\": [], \"lr\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be89142b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    for batch in train_loader:\n",
    "        images, points, labels = batch['rgb_depths'].to(device), batch['xyz_rgbs'].to(device), batch['labels'].to(device)\n",
    "        label_coordinates, label_angles = labels[:,:3], labels[:,3:]\n",
    "        y = torch.ones(label_angles.size(0), device=device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images, points)\n",
    "        output_coordinates, output_angles = outputs[:,:3], outputs[:,3:]\n",
    "        coordinate_loss = coordinate_criterion(output_coordinates, label_coordinates)\n",
    "        angle_loss = angle_criterion(output_angles, label_angles, y)\n",
    "        loss = coordinate_loss * LAMBDA + angle_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    history['train_loss'].append(avg_train_loss)\n",
    "\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    total_val_mce = 0\n",
    "    total_val_oe = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            images, points, labels = batch['rgb_depths'].to(device), batch['xyz_rgbs'].to(device), batch['labels'].to(device)\n",
    "            label_coordinates, label_angles = labels[:,:3], labels[:,3:]\n",
    "            y = torch.ones(label_angles.size(0), device=device)\n",
    "\n",
    "            outputs = model(images, points)\n",
    "            output_coordinates, output_angles = outputs[:,:3], outputs[:,3:]\n",
    "            coordinate_loss = coordinate_criterion(output_coordinates, label_coordinates)\n",
    "            angle_loss = angle_criterion(output_angles, label_angles, y)\n",
    "            loss = coordinate_loss * LAMBDA + angle_loss\n",
    "            mce = MCE(output_coordinates, label_coordinates)\n",
    "            oe = OE(output_angles, label_angles)\n",
    "\n",
    "            total_val_loss += loss.item()\n",
    "            total_val_mce += mce.item()\n",
    "            total_val_oe += oe.item()\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    avg_val_mce = total_val_mce / len(val_loader)\n",
    "    avg_val_oe = total_val_oe / len(val_loader)\n",
    "    val_ac = AC(avg_val_mce, avg_val_oe)\n",
    "    history['val_loss'].append(avg_val_loss)\n",
    "    history['val_mce'].append(avg_val_mce)\n",
    "    history['val_oe'].append(avg_val_oe)\n",
    "    history['val_ac'].append(val_ac)\n",
    "\n",
    "    scheduler.step(avg_val_loss)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    history['lr'].append(current_lr)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}] | Training Loss: {avg_train_loss:.5f} | Validation Loss: {avg_val_loss:.5f} | MCE: {avg_val_mce:.5f} | OE: {avg_val_oe:.5f} | AC: {val_ac:.5f} | Learning Rate: {current_lr:.1e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21745443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with 3 subplots (stacked vertically)\n",
    "fig, axes = plt.subplots(3, 1, figsize=(10, 12))\n",
    "\n",
    "# Plot 1: Training and Validation Loss\n",
    "axes[0].plot(history[\"train_loss\"], label=\"Train Loss\", marker='o')\n",
    "axes[0].plot(history[\"val_loss\"], label=\"Validation Loss\", marker='o')\n",
    "axes[0].set_title(\"Training and Validation Loss\")\n",
    "axes[0].set_xlabel(\"Epoch\")\n",
    "axes[0].set_ylabel(\"Loss\")\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Plot 2: Validation MCE and OE\n",
    "axes[1].plot(history[\"val_mce\"], label=\"MCE\", marker='s')\n",
    "axes[1].plot(history[\"val_oe\"], label=\"OE\", marker='^')\n",
    "axes[1].plot(history[\"val_ac\"], label=\"AC\", marker='d')\n",
    "axes[1].set_title(\"Validation Metrics: MCE, OE and AC\")\n",
    "axes[1].set_xlabel(\"Epoch\")\n",
    "axes[1].set_ylabel(\"Error\")\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "# Plot 3: Learning Rate\n",
    "axes[2].plot(history[\"lr\"], label=\"Learning Rate\", color='purple', marker='x')\n",
    "axes[2].set_title(\"Learning Rate Schedule\")\n",
    "axes[2].set_xlabel(\"Epoch\")\n",
    "axes[2].set_ylabel(\"Learning Rate\")\n",
    "axes[2].set_yscale(\"log\")  # Learning rate often benefits from log scale\n",
    "axes[2].legend()\n",
    "axes[2].grid(True)\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640b9e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        images, points = batch['rgb_depths'].to(device), batch['xyz_rgbs'].to(device)\n",
    "        outputs = model(images, points)\n",
    "        coordinates, angles = outputs[:,:3], outputs[:,3:]\n",
    "        normalized_angles = angles / torch.norm(angles, dim=1, keepdim=True)\n",
    "        names = batch['names']\n",
    "\n",
    "        for i, name in enumerate(names):\n",
    "            row = {\n",
    "                'image_filename': name,\n",
    "                'x': coordinates[i, 0].item(),\n",
    "                'y': coordinates[i, 1].item(),\n",
    "                'z': coordinates[i, 2].item(),\n",
    "                'Rx': normalized_angles[i, 0].item(),\n",
    "                'Ry': normalized_angles[i, 1].item(),\n",
    "                'Rz': normalized_angles[i, 2].item(),\n",
    "            }\n",
    "            results.append(row)\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df = df.sort_values(by='image_filename').reset_index(drop=True)\n",
    "df.to_csv('Submission_3D.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdce5342",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
